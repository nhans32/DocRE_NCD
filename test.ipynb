{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from utils import set_seed\n",
    "\n",
    "set_seed(1234)\n",
    "os.environ['HF_HOME'] = 'hf_cache' # Don't want model files in our home directory due to disk quota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/nhanse02/thesis/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('studio-ousia/luke-large', add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   0, 1308,  766,   16, 2651,  479,    2,    1,    1],\n",
       "        [   0, 1190,   16,   10, 1441,    9, 2722,  479,    2]]), 'entity_ids': tensor([[2, 0],\n",
       "        [2, 2]]), 'entity_position_ids': tensor([[[ 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]],\n",
       "\n",
       "        [[ 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [ 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'entity_attention_mask': tensor([[1, 0],\n",
       "        [1, 1]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = [\"My name is Nick.\", \"Mark is a friend of Jack.\"]\n",
    "spans = [[(11, 15)], [(0, 4), (20, 24)]]\n",
    "\n",
    "tokenizer(txt, entity_spans=spans, return_tensors='pt', padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/nhanse02/thesis/data/train_annotated.json: 100%|██████████| 3053/3053 [00:25<00:00, 118.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils import read_docred\n",
    "import json\n",
    "\n",
    "samples = read_docred(fp='/data2/nhanse02/thesis/data/train_annotated.json', rel2id=json.load(open('data/meta/rel2id.json')), tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  1,   2,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 61,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 97,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [  5,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 21,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 23,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 32,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 40,  41,  42,  43,  -1,  -1,  -1,  -1,  -1],\n",
      "         [138,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [148,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 34,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 49,  50,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 52,  53,  54,  55,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 58,  59,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 82,  83,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 79,  80,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 85,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [101, 102,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [104,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [106,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [108,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [110, 111,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [113,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [116, 117,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [122,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [124, 125,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [127, 128,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [130,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [132,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [134,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [144,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [146,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1]],\n",
      "\n",
      "        [[  1,   2,   3,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [  9,  10,  11,  12,  13,  14,  -1,  -1,  -1],\n",
      "         [ 12,  13,  14,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 18,  19,  20,  21,  22,  23,  24,  -1,  -1],\n",
      "         [ 54,  55,  56,  57,  58,  -1,  -1,  -1,  -1],\n",
      "         [ 63,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 83,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 88,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 91,  92,  93,  94,  95,  -1,  -1,  -1,  -1],\n",
      "         [105,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [110, 111, 112,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [121,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [127, 128, 129, 130,  -1,  -1,  -1,  -1,  -1],\n",
      "         [141, 142, 143, 144,  -1,  -1,  -1,  -1,  -1],\n",
      "         [151, 152, 153,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1]],\n",
      "\n",
      "        [[  1,   2,   3,   4,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 11,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 14,  15,  16,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [103, 104, 105,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 22,  23,  24,  25,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 28,  29,  30,  31,  32,  33,  34,  35,  36],\n",
      "         [ 52,  53,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 55,  56,  57,  58,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 67,  68,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 71,  72,  73,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 83,  84,  85,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ 89,  90,  91,  92,  -1,  -1,  -1,  -1,  -1],\n",
      "         [122, 123, 124,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [126, 127, 128,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [145, 146, 147, 148, 149, 150, 151, 152, 153],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "         [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1]]])\n"
     ]
    }
   ],
   "source": [
    "from utils import collate_fn\n",
    "\n",
    "print(collate_fn(samples[15:18])['entity_position_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
